{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Story on Venmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Source Materials I\n",
    "[X] names, use wordvector to grab similar items from moive script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using names from moive 500 days of summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summer = nlp(open(\"lalaland.txt\").read())\n",
    "tokens_summer = list(set([w.text for w in summer if w.is_alpha]))\n",
    "\n",
    "breakItDown = nlp(open(\"titanic.txt\").read())\n",
    "tokens_breakItDown = list(set([w.text for w in breakItDown if w.is_alpha]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find similar items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec(s):\n",
    "    return nlp.vocab[s].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine(v1, v2):\n",
    "    if norm(v1) > 0 and norm(v2) > 0:\n",
    "        return dot(v1, v2) / (norm(v1) * norm(v2))\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spacy_closest(token_list, vec_to_check, n=20):\n",
    "    return sorted(token_list,\n",
    "                 key=lambda x: cosine(vec_to_check, vec(x)),\n",
    "                 reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natalie', 'Rachel', 'Pfeiffer', 'Michelle', 'ALEXIS', 'Alexis', 'Amy', 'AMY', 'Caitlin', 'CAITLIN', 'Tracy', 'TRACY', 'Jen', 'Miranda', 'Laura', 'Ingrid', 'LAURA', 'Josh', 'JOSH', 'James', 'SEBASTIAN', 'Sebastian', 'DAVID', 'David', 'Benny', 'Monica', 'Michael', 'DOLAN', 'Dolan', 'George', 'Pfeiffer', 'Michelle', 'ALEXIS', 'Alexis', 'James', 'Eddie', 'GREG', 'Greg', 'Miranda', 'Laura']\n"
     ]
    }
   ],
   "source": [
    "name_female = spacy_closest(tokens_summer, vec(\"Rachel\"))\n",
    "name_male = spacy_closest(tokens_summer,vec(\"Sebastian\"))\n",
    "name = name_female + name_male\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def meanv(coords):\n",
    "    sumv = [0] * len(coords[0])\n",
    "    for item in coords:\n",
    "        for i in range(len(item)):\n",
    "            sumv[i] += item[i]\n",
    "    mean = [0] * len(sumv)\n",
    "    for i in range(len(sumv)):\n",
    "        mean[i] = float(sumv[i]) / len(coords)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentvec(s):\n",
    "    sent = nlp(s)\n",
    "    return meanv([w.vector for w in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences_summer = list(summer.sents)\n",
    "sentences_breakItDown = list(breakItDown.sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Source Materials II\n",
    "[x] memo, use wordvector to grab similar sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spacy_closest_sent(space, input_str, n=30):\n",
    "    input_vec = sentvec(input_str)\n",
    "    return sorted(space,\n",
    "                  key=lambda x: cosine(np.mean([w.vector for w in x], axis=0), input_vec), \n",
    "                  reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-959c8cc6a6d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msmall_payment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmall_payment\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msmall_adj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmall_adj_good\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msmall_adj_bad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0myup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'yup' is not defined"
     ]
    }
   ],
   "source": [
    "small_adj_good = spacy_closest(tokens_breakItDown,vec(\"fantastic\"))\n",
    "small_adj_bad = spacy_closest(tokens_breakItDown,vec(\"stupid\"))\n",
    "small_payment = spacy_closest(tokens_breakItDown,vec(\"salad\"))\n",
    "events = spacy_closest(tokens_breakItDown,vec(\"concert\"))\n",
    "num = spacy_closest(tokens_breakItDown,vec(\"half\"))\n",
    "small_payment = small_payment + events\n",
    "small_adj = small_adj_good + small_adj_bad\n",
    "yup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I swear to God, if I have to hear one more hipster waxing nostalgic',\n",
       " 'They share a moment -- share a look -- jump off -- AND START REALLY DANCING NOW...',\n",
       " 'But I love it too much.',\n",
       " 'I love this stuff.',\n",
       " 'This looks fun.',\n",
       " \"I'm always going to love you too.\",\n",
       " \"You're too modest to say it\",\n",
       " \"I've tried so hard to want other things.\",\n",
       " 'I had a very serious plan for my future.',\n",
       " 'MIA ...Because it hurts a little bit too much.',\n",
       " 'A shared smile.',\n",
       " \"But I'm not expecting to find anything out.\",\n",
       " \"So you're happy here?\",\n",
       " 'Get my own thing going.',\n",
       " \"I'm grabbing some pastries, you two want anything?\",\n",
       " 'People love what other people are passionate about.',\n",
       " 'So you could write your own roles.',\n",
       " \"I've got to follow my own plan.\",\n",
       " 'I have to grab a drink...',\n",
       " \"Maybe I'm one of those people who's always wanted to do it but never had a chance.\",\n",
       " 'So exciting!',\n",
       " 'So I look at Sebastian... Playing music, getting paid for it.',\n",
       " \"I'm finally doing something that people enjoy.\",\n",
       " \"They're more polished in their looks than Sebastian.\",\n",
       " \"Mia's ROOMMATES are there, giddy with joy, as are LAURA and HARRY...\",\n",
       " 'I have someone I want you to meet.',\n",
       " \"Guys like me go their whole lives and never do anything that's liked.\",\n",
       " \"There's nothing to make fun of.\",\n",
       " 'Honestly, I wish I loved something else.',\n",
       " \"and you're going to love it.\",\n",
       " 'The Baked Potato was gonna throw it away.',\n",
       " 'Roast chicken.',\n",
       " \"I'm grabbing some pastries, you two want anything?\",\n",
       " \"This doesn't taste like almond milk.\",\n",
       " \"they'd play at cocktail parties whenever they served the salami and cheese.\",\n",
       " 'Drop the chicken.',\n",
       " \"It's definitely Chicken on a Stick --\",\n",
       " \"I'll eat it\",\n",
       " 'Pasta.',\n",
       " 'Chicken on a Stick\".',\n",
       " 'You want some more rice?',\n",
       " \"So my club's gonna be old-school jazz and beer and chicken.\",\n",
       " \"Getting up to scrape the dish -- MIA'S DAD\",\n",
       " '\"Bird\" because he loved chicken.',\n",
       " 'It slams shut, as Sebastian pulls the burnt apple pie from the oven.',\n",
       " \"He heads to the kitchen, pulls out some pork cutlets he's been thawing.\",\n",
       " 'He looks idiotic.',\n",
       " \"Either they interrupt me because someone ordered a sandwich, or they cut me off after two seconds, or I'm crying and they start laughing,\",\n",
       " 'Is the whole thing too nostalgic?',\n",
       " \"KEITH Let's just grab a drink then.\",\n",
       " \"Why do you say romantic like it's a dirty word?\",\n",
       " 'Tracy has wandered in -- pajamas, eating cereal.',\n",
       " 'I swear to God, if I have to hear one more hipster waxing nostalgic',\n",
       " 'but it tastes good.',\n",
       " '\"Chicken on a Stick\".',\n",
       " 'Ok I was an asshole.',\n",
       " 'MIA ...Because it hurts a little bit too much.',\n",
       " 'CUSTOMER Are these pastries gluten-free?',\n",
       " 'Turn off here and get dinner?',\n",
       " \"-- just so annoying, I mean you're trying to watch a movie --\",\n",
       " 'so you could take care of yourself and start your club.',\n",
       " 'Maybe you liked me more when I was a failure because it made you feel better about yourself.',\n",
       " \"There are four things in my inbox that you're perfect for and I will submit you.\",\n",
       " 'Well now I see how you can look down on me from all the way up there.',\n",
       " \"It matters if you're going to give up your dream to be on the road for years.\",\n",
       " \"I don't want you uncomfortable and trying to change this into something it's not.\",\n",
       " \"And now I hear you're going to be on the road for years, and I'm --\",\n",
       " 'I made something for you.',\n",
       " \"but I think someone's trying to break into your car.\",\n",
       " \"I've tried so hard to want other things.\",\n",
       " \"I mean the long haul -- like, you're going to be in this band for a long time.\",\n",
       " \"But I'm not expecting to find anything out.\",\n",
       " \"Guys like me go their whole lives and never do anything that's liked.\",\n",
       " \"I can't let them samba all over its history.\",\n",
       " \"Alright, one more for y'all before we break.\",\n",
       " 'I told you not to get me anything!',\n",
       " \"You don't live as long, but you get things done faster, so it all evens out.\",\n",
       " \"I can find something else that I'm supposed to do.\",\n",
       " \"You didn't give me much of a choice.\",\n",
       " 'Get my own thing going.',\n",
       " \"and you're going to love it.\",\n",
       " \"but when I have my own place -- my club -- they'll play whatever they want.\",\n",
       " \"Maybe I'm one of those people who's always wanted to do it but never had a chance.\",\n",
       " \"I'm always going to love you too.\",\n",
       " \"I haven't heard from you in a while...\",\n",
       " 'Or all for you, none for me?',\n",
       " \"what you don't understand is, I want to be on the ropes.\",\n",
       " \"When you get this -- you've got to give it everything you've got.\",\n",
       " \"If it's not your thing, just let me know.\",\n",
       " 'If you want -- I can take you.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memo_1 = []\n",
    "memo_2 = []\n",
    "memo_3 = []\n",
    "\n",
    "for sent in spacy_closest_sent(sentences_summer, \"Share Uber\"):\n",
    "    memo_1.append(\" \".join(sent.text.split()))\n",
    "for sent in spacy_closest_sent(sentences_summer, \"stupid salad\"):\n",
    "    memo_2.append(\" \".join(sent.text.split()))\n",
    "for sent in spacy_closest_sent(sentences_summer, \"I feel bad for taking all your drugs\"):\n",
    "# for sent in spacy_closest_sent(sentences_summer, \"Thank you for saving my life.\"):\n",
    "    memo_3.append(\" \".join(sent.text.split()))\n",
    "memo = memo_1 + memo_2 + memo_3\n",
    "memo\n",
    "# print(len(memo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Source Materials III\n",
    "[X] money, use regular expression to grab numbers end with $ from movie script  \n",
    "[X] time, use regular expression to grab numbers with time format from moive script  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combine all scripts in one folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/ericli/rwet-notebooks/reading-and-writing-electronic-text/moive_scripts/'\n",
    "moive_lines = []\n",
    "for filename in glob.glob(os.path.join(path, '*.txt')):\n",
    "    moive_temp = open(filename).readlines()\n",
    "    moive_lines_temp = [line.strip() for line in moive_temp]\n",
    "    moive_lines.extend(moive_lines_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find all time without AM/PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_line = [line for line in moive_lines if re.search(r\"\\d:\\d\\d\", line)]\n",
    "time_list = [re.findall(r\"\\d?\\d:\\d\\d\", item) for item in time_line]\n",
    "time = []\n",
    "\n",
    "for i in range(0,len(time_list)):\n",
    "    for j in range(0,len(time_list[i])):\n",
    "        time.append(time_list[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find all money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "money_line = [line for line in moive_lines if re.search(r\"\\$\", line)]\n",
    "money_list = [re.findall(r\"\\$[1-9]\\d?\\d?\\.?\\d\\d\", item) for item in money_line]\n",
    "\n",
    "money = []\n",
    "for i in range(0,len(money_list)):\n",
    "    for j in range(0,len(money_list[i])):\n",
    "        money.append(money_list[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate 500 days dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monthArr = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\",\"December\"]\n",
    "dates = []\n",
    "datesNum = []\n",
    "\n",
    "for i in range(0, 30):\n",
    "    days = random.randint(1, 500)\n",
    "    datesNum.append(days)\n",
    "\n",
    "datesNumSorted = sorted(datesNum)\n",
    "\n",
    "for j in range(0,len(datesNumSorted)):\n",
    "    monthNum = int(datesNumSorted[j]/30)\n",
    "    days = datesNumSorted[j]%30\n",
    "    if(days == 0):\n",
    "        days = 30\n",
    "    if(monthNum > 11):\n",
    "        month = monthArr[monthNum-11]\n",
    "        year = \"2018\"\n",
    "    else:\n",
    "        month = monthArr[monthNum]\n",
    "        year = \"2017\"\n",
    "    \n",
    "    date_str = month+\" \"+str(days)+\", \"+year\n",
    "    dates.append(date_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Materials IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shmarkov import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def markov_model_from_sequences(n, sequences):\n",
    "    model = {}\n",
    "    for item in sequences:\n",
    "        add_to_model(model, n, item)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Venmo template\n",
    "Venmo template through tracery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tracery\n",
    "from tracery.modifiers import base_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:30 am, January 5, 2017\n",
      "Mia charged Tom \t$1.25 \n",
      " ❤️, ❤️, And you're going to love it.\n",
      "--------------------------------\n",
      "10:30 am, January 10, 2017\n",
      "Tom paid Mia \t$500 \n",
      " 💃, perfect musical, 💸, I'm always going to love you too.\n",
      "--------------------------------\n",
      "7:00 am, January 16, 2017\n",
      "Tom paid Mia \t$250 \n",
      " bad tickets, stunning meat, 💊, What you don't understand is, i want to be on the ropes.\n",
      "--------------------------------\n",
      "7:05 am, January 17, 2017\n",
      "Mia charged Tom \t$700 \n",
      " beautiful salad, 💡🔌, 🍺, People love what other people are passionate about.\n",
      "--------------------------------\n",
      "5:44 am, February 11, 2017\n",
      "Tom charged Mia \t$1.49 \n",
      " wrong dinner, 🍃, amazingly juice, Alright, one more for y'all before we break.\n",
      "--------------------------------\n",
      "5:45 pm, April 4, 2017\n",
      "Josh paid Greg \t$4.50 \n",
      " fabulous swede, 🍷, Ok i was an asshole.\n",
      "--------------------------------\n",
      "6:29 pm, April 13, 2017\n",
      "Tom paid Mia \t$2400 \n",
      " rediculous meat, hell band, 💃, I'm grabbing some pastries, you two want anything?\n",
      "--------------------------------\n",
      "6:17 am, June 5, 2017\n",
      "Mia paid Tom \t$1.79 \n",
      " good music, 🍃, I don't want you uncomfortable and trying to change this into something it's not.\n",
      "--------------------------------\n",
      "4:13 am, June 15, 2017\n",
      "Mia paid Tom \t$84.75 \n",
      " stunningly tickets, 😽, amazing iceberg, People love what other people are passionate about.\n",
      "--------------------------------\n",
      "6:20 pm, July 26, 2017\n",
      "Mia charged Tom \t$250 \n",
      " 🍔, Get my own thing going.\n",
      "--------------------------------\n",
      "7:25 am, August 11, 2017\n",
      "Tracy charged Greg \t$1.98 \n",
      " idiot sauce, electrifying lemon, idiot orchestra, But it tastes good.\n",
      "--------------------------------\n",
      "10:15 am, August 12, 2017\n",
      "Tom charged Mia \t$21.69 \n",
      " 💡🔌, 💃, hell lemon, \"bird\" because he loved chicken.\n",
      "--------------------------------\n",
      "10:15 pm, August 16, 2017\n",
      "Tom charged Mia \t$800 \n",
      " I haven't heard from you in a while...\n",
      "--------------------------------\n",
      "3:30 pm, August 21, 2017\n",
      "Alexis paid Michael \t$300 \n",
      " 🍜, brilliant touring, You want some more rice?\n",
      "--------------------------------\n",
      "3:45 am, August 29, 2017\n",
      "Mia paid Tom \t$2000 \n",
      " 💸, Or all for you, none for me?\n",
      "--------------------------------\n",
      "4:00 am, September 5, 2017\n",
      "Mia paid Tom \t$21.69 \n",
      " wrong tickets, shit ragtime, fool marmalade, You didn't give me much of a choice.\n",
      "--------------------------------\n",
      "4:30 am, October 19, 2017\n",
      "Mia charged Tom \t$200 \n",
      " 💃, funny tour, I've got to follow my own plan.\n",
      "--------------------------------\n",
      "5:00 am, November 25, 2017\n",
      "Michelle paid Pfeiffer \t$900 \n",
      " 🚕, 🔥, What you don't understand is, i want to be on the ropes.\n",
      "--------------------------------\n",
      "5:45 am, December 13, 2017\n",
      "Tom paid Mia \t$100 \n",
      " shit dinner, 🔥, It's definitely chicken on a stick --\n",
      "--------------------------------\n",
      "4:15 am, December 14, 2017\n",
      "Tom charged Mia \t$325 \n",
      " 🎉, perfect dinner, I'm always going to love you too.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "rules = {\n",
    "    \"origin\": [\n",
    "        \"#name.lowercase.capitalize# #action# #name.lowercase.capitalize# \\t#money# \\n#emojiset##emojiset##emojiset# #memo.lowercase.capitalize#\",\n",
    "        \"Tom #action# Mia \\t#money# \\n#emojiset##emojiset##emojiset# #memo.lowercase.capitalize#\",\n",
    "        \"Mia #action# Tom \\t#money# \\n#emojiset##emojiset##emojiset# #memo.lowercase.capitalize#\",\n",
    "        \"Tom #action# Mia \\t#money# \\n#emojiset##emojiset##emojiset# #memo.lowercase.capitalize#\",\n",
    "        \"Mia #action# Tom \\t#money# \\n#emojiset##emojiset##emojiset# #memo.lowercase.capitalize#\",\n",
    "              ],\n",
    "    \"name\": name,\n",
    "    \"money\":money,\n",
    "    \"action\":[\"paid\", \"charged\"],\n",
    "    \"date\":[\"#time#, #dates#\"],\n",
    "    \"time\":[\"#timedigits# #clock#\"],\n",
    "    \"timedigits\": time,\n",
    "    \"clock\":[\"am\",\"pm\"],\n",
    "    \"dates\":dates,\n",
    "    \"memo\":memo,\n",
    "    \"emojiset\":[\" #emoji#,\",\" #small_adj.lowercase# #smallPayment.lowercase#,\",\"\"],\n",
    "    \"small_adj\":small_adj,\n",
    "    \"smallPayment\":small_payment,\n",
    "    \"emoji\":[\"💊\",\"🎉\",\"🏡\",\"🍜\",\"🔥\",\"😽\",\"🍷\",\"💃\",\"❤️\",\"🍺\",\"🍣\",\"🍔\",\"🍃\",\"🍕\",\"🚕\",\"💸\",\"💡🔌\"],\n",
    "}\n",
    "clock = [\"am\",\"pm\"]\n",
    "\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "for i in range(20):\n",
    "    print(time[i],random.choice(clock)+\",\",dates[i])\n",
    "    print(grammar.flatten(\"#origin#\"))\n",
    "    print(\"--------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
